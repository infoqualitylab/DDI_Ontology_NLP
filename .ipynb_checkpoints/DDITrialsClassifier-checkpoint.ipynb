{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Article Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Publication Type</th>\n",
       "      <th>Methods Section</th>\n",
       "      <th>First Label</th>\n",
       "      <th>Second Label</th>\n",
       "      <th>hydroxymethylglutaryl</th>\n",
       "      <th>acetaminophen</th>\n",
       "      <th>alfentanyl</th>\n",
       "      <th>...</th>\n",
       "      <th>tramadol</th>\n",
       "      <th>trazodone</th>\n",
       "      <th>triazolam</th>\n",
       "      <th>valproate</th>\n",
       "      <th>venlafaxine</th>\n",
       "      <th>verapamil</th>\n",
       "      <th>voriconazole</th>\n",
       "      <th>warfarin</th>\n",
       "      <th>ziprasidone</th>\n",
       "      <th>zolpidem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8646822</td>\n",
       "      <td>A kinetic and dynamic study of oral alprazolam...</td>\n",
       "      <td>To assess the possible involvement of CYP3A4 i...</td>\n",
       "      <td>Clinical Trial ;Journal Article ;Randomized Co...</td>\n",
       "      <td>methods subjects twelve unrelated healthy male...</td>\n",
       "      <td>DDI Clinical Trial</td>\n",
       "      <td>RCT DDI Clinical Trial</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8453848</td>\n",
       "      <td>A potentially hazardous interaction between er...</td>\n",
       "      <td>Interaction between erythromycin and midazolam...</td>\n",
       "      <td>Clinical Trial ;Journal Article ;Randomized Co...</td>\n",
       "      <td>material and methods study design orally admin...</td>\n",
       "      <td>DDI Clinical Trial</td>\n",
       "      <td>RCT DDI Clinical Trial</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23210726</td>\n",
       "      <td>A semi-mechanistic absorption model to evaluat...</td>\n",
       "      <td>The aim of this study was to develop a PK/PD m...</td>\n",
       "      <td>Journal Article ;Randomized Controlled Trial ;...</td>\n",
       "      <td>methods ten healthy male volunteers randomized...</td>\n",
       "      <td>DDI Clinical Trial</td>\n",
       "      <td>RCT DDI Clinical Trial</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11936570</td>\n",
       "      <td>A study of the interaction potential of azithr...</td>\n",
       "      <td>Atorvastatin is a common option among the HMG-...</td>\n",
       "      <td>Clinical Trial ;Clinical Trial, Phase I ;Compa...</td>\n",
       "      <td>materials and methods this randomized open lab...</td>\n",
       "      <td>DDI Clinical Trial</td>\n",
       "      <td>RCT DDI Clinical Trial</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1387301</td>\n",
       "      <td>Absolute bioavailability of clarithromycin aft...</td>\n",
       "      <td>The absolute bioavailability of clarithromycin...</td>\n",
       "      <td>Clinical Trial ;Comparative Study ;Journal Art...</td>\n",
       "      <td>clarithromycin new 14 membered macrolide antim...</td>\n",
       "      <td>PK Trial</td>\n",
       "      <td>PK Trial</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID                                      Article Title  \\\n",
       "0   8646822  A kinetic and dynamic study of oral alprazolam...   \n",
       "1   8453848  A potentially hazardous interaction between er...   \n",
       "2  23210726  A semi-mechanistic absorption model to evaluat...   \n",
       "3  11936570  A study of the interaction potential of azithr...   \n",
       "4   1387301  Absolute bioavailability of clarithromycin aft...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  To assess the possible involvement of CYP3A4 i...   \n",
       "1  Interaction between erythromycin and midazolam...   \n",
       "2  The aim of this study was to develop a PK/PD m...   \n",
       "3  Atorvastatin is a common option among the HMG-...   \n",
       "4  The absolute bioavailability of clarithromycin...   \n",
       "\n",
       "                                    Publication Type  \\\n",
       "0  Clinical Trial ;Journal Article ;Randomized Co...   \n",
       "1  Clinical Trial ;Journal Article ;Randomized Co...   \n",
       "2  Journal Article ;Randomized Controlled Trial ;...   \n",
       "3  Clinical Trial ;Clinical Trial, Phase I ;Compa...   \n",
       "4  Clinical Trial ;Comparative Study ;Journal Art...   \n",
       "\n",
       "                                     Methods Section         First Label  \\\n",
       "0  methods subjects twelve unrelated healthy male...  DDI Clinical Trial   \n",
       "1  material and methods study design orally admin...  DDI Clinical Trial   \n",
       "2  methods ten healthy male volunteers randomized...  DDI Clinical Trial   \n",
       "3  materials and methods this randomized open lab...  DDI Clinical Trial   \n",
       "4  clarithromycin new 14 membered macrolide antim...            PK Trial   \n",
       "\n",
       "             Second Label  hydroxymethylglutaryl  acetaminophen  alfentanyl  \\\n",
       "0  RCT DDI Clinical Trial                      0              0           0   \n",
       "1  RCT DDI Clinical Trial                      0              0           0   \n",
       "2  RCT DDI Clinical Trial                      0              0           0   \n",
       "3  RCT DDI Clinical Trial                      0              0           0   \n",
       "4                PK Trial                      0              0           0   \n",
       "\n",
       "     ...     tramadol  trazodone  triazolam  valproate  venlafaxine  \\\n",
       "0    ...            0          0          0          0            0   \n",
       "1    ...            0          0          0          0            0   \n",
       "2    ...            0          0          0          0            0   \n",
       "3    ...            0          0          0          0            0   \n",
       "4    ...            0          0          0          0            0   \n",
       "\n",
       "   verapamil  voriconazole  warfarin  ziprasidone  zolpidem  \n",
       "0          0             0         0            0         0  \n",
       "1          0             0         0            0         0  \n",
       "2          0             0         0            0         0  \n",
       "3          0             0         0            0         0  \n",
       "4          0             0         0            0         0  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/phuong/Documents/AAAI_Project/All_Articles.csv',encoding ='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "col = ['Article Title','Abstract','Methods Section','First Label','Second Label']\n",
    "df = df[col]\n",
    "df = df[pd.notnull(df['Abstract'])]\n",
    "\n",
    "#generate categorize_id level 1 based on First Label\n",
    "df.columns = ['Article Title','Abstract','Methods Section','First Label','Second Label']\n",
    "df['category_id_1'] = df['First Label'].factorize()[0]\n",
    "category_id_df = df[['First Label', 'category_id_1']].drop_duplicates().sort_values('category_id_1')\n",
    "category_to_id = dict(category_id_df.values)\n",
    "id_to_category = dict(category_id_df[['category_id_1', 'First Label']].values)\n",
    "\n",
    "#generate categorize_id level 2 based on Second Label\n",
    "df['category_id_2'] = df['Second Label'].factorize()[0]\n",
    "category_id_df_2 = df[['Second Label', 'category_id_2']].drop_duplicates().sort_values('category_id_2')\n",
    "category_to_id_2 = dict(category_id_df_2.values)\n",
    "id_to_category_2 = dict(category_id_df_2[['category_id_2', 'Second Label']].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hydroxymethylglutaryl</th>\n",
       "      <th>acetaminophen</th>\n",
       "      <th>alfentanyl</th>\n",
       "      <th>alitretinoin</th>\n",
       "      <th>alosetron</th>\n",
       "      <th>alprazolam</th>\n",
       "      <th>ambrisentan</th>\n",
       "      <th>amiodarone</th>\n",
       "      <th>amitriptyline</th>\n",
       "      <th>amlodipine</th>\n",
       "      <th>...</th>\n",
       "      <th>tramadol</th>\n",
       "      <th>trazodone</th>\n",
       "      <th>triazolam</th>\n",
       "      <th>valproate</th>\n",
       "      <th>venlafaxine</th>\n",
       "      <th>verapamil</th>\n",
       "      <th>voriconazole</th>\n",
       "      <th>warfarin</th>\n",
       "      <th>ziprasidone</th>\n",
       "      <th>zolpidem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hydroxymethylglutaryl  acetaminophen  alfentanyl  alitretinoin  alosetron  \\\n",
       "0                      0              0           0             0          0   \n",
       "1                      0              0           0             0          0   \n",
       "2                      0              0           0             0          0   \n",
       "3                      0              0           0             0          0   \n",
       "4                      0              0           0             0          0   \n",
       "\n",
       "   alprazolam  ambrisentan  amiodarone  amitriptyline  amlodipine    ...     \\\n",
       "0           1            0           0              0           0    ...      \n",
       "1           0            0           0              0           0    ...      \n",
       "2           0            0           0              0           0    ...      \n",
       "3           0            0           0              0           0    ...      \n",
       "4           0            0           0              0           0    ...      \n",
       "\n",
       "   tramadol  trazodone  triazolam  valproate  venlafaxine  verapamil  \\\n",
       "0         0          0          0          0            0          0   \n",
       "1         0          0          0          0            0          0   \n",
       "2         0          0          0          0            0          0   \n",
       "3         0          0          0          0            0          0   \n",
       "4         0          0          0          0            0          0   \n",
       "\n",
       "   voriconazole  warfarin  ziprasidone  zolpidem  \n",
       "0             0         0            0         0  \n",
       "1             0         0            0         0  \n",
       "2             0         0            0         0  \n",
       "3             0         0            0         0  \n",
       "4             0         0            0         0  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the drug entities features\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv('/Users/phuong/Documents/AAAI_Project/All_Drug_Entities_Features.csv',encoding ='latin1')\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185, 100113)\n",
      "Row 4 has been classified as  0 and should be  1\n",
      "Row 5 has been classified as  0 and should be  1\n",
      "Row 6 has been classified as  0 and should be  1\n",
      "Row 13 has been classified as  0 and should be  1\n",
      "Row 16 has been classified as  0 and should be  1\n",
      "Row 25 has been classified as  0 and should be  1\n",
      "Row 26 has been classified as  0 and should be  1\n",
      "Row 27 has been classified as  0 and should be  1\n",
      "Row 31 has been classified as  0 and should be  1\n",
      "Row 32 has been classified as  0 and should be  1\n",
      "[[28  0]\n",
      " [ 8  1]]\n",
      "28 0 8 1\n",
      "Accuracy: 0.7837837837837838\n",
      "ROC AUC:  0.5555555555555556\n",
      "Precision: 0.8318318318318318\n",
      "Recall: 0.7837837837837838\n",
      "F1 score: 0.7108108108108109\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        28\n",
      "           1       1.00      0.11      0.20         9\n",
      "\n",
      "   micro avg       0.78      0.78      0.78        37\n",
      "   macro avg       0.89      0.56      0.54        37\n",
      "weighted avg       0.83      0.78      0.71        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#First layer Classifier: SVM - DDI Clinical Trials vs. PK Trials\n",
    "%matplotlib inline\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# SVM Model with bigrams taken from Abstract, Article Title, & Methods Section text\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, cross_val_predict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix,roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.fixes import signature\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "#Get bigrams from Title. Abstract, Methods Section\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "text = df['Abstract'] + df['Article Title'] + df['Methods Section']\n",
    "bigram_features = vectorizer.fit_transform(text)\n",
    "print (bigram_features.shape)\n",
    "\n",
    "X_train_dtm = bigram_features\n",
    "for column in df1.columns[1:]:\n",
    "    X_train_dtm = hstack((X_train_dtm,np.array(df1[column])[:,None]))\n",
    "labels_level_1 = df.category_id_1\n",
    "labels_level_2 = df.category_id_2\n",
    "\n",
    "\n",
    "#Train SVM model using the bigram features\n",
    "X_train, X_test, y_train, y_test,  = train_test_split(X_train_dtm, labels_level_1, stratify = labels_level_1, test_size=0.2, random_state = 0)\n",
    "model = SVC(kernel='linear', class_weight='balanced')\n",
    "clf = model.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "#Print out the row that are misclassified\n",
    "for row_index, (X_test_item, prediction, label) in enumerate(zip (X_test, predictions, labels_level_1)):\n",
    "  if prediction != label:\n",
    "    print('Row', row_index, 'has been classified as ', prediction, 'and should be ', label)\n",
    "\n",
    "#Print out confusion matrix, True Positive, True Negative, False Positive, False Negative\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print (tn, fp, fn, tp)\n",
    "\n",
    "#Print Accurancy, ROC AUC, F1 Scores, Recall, Precision)\n",
    "print ('Accuracy:', accuracy_score(y_test, predictions))\n",
    "print ('ROC AUC: ', roc_auc_score(y_test,predictions))\n",
    "print ('Precision:', precision_score(y_test, predictions,\n",
    "                                    average='weighted'))\n",
    "print ('Recall:', recall_score(y_test, predictions,\n",
    "                              average='weighted'))\n",
    "print ('F1 score:', f1_score(y_test, predictions,average='weighted'))\n",
    "print (classification_report(y_test,predictions))\n",
    "\n",
    "\n",
    "# #------------------------------\n",
    "# #Plot Precision-Recall Curve\n",
    "# precision, recall, _ = precision_recall_curve(y_test, predictions)\n",
    "# step_kwargs = ({'step': 'post'}\n",
    "#                if 'step' in signature(plt.fill_between).parameters\n",
    "#                else {})\n",
    "# plt.step(recall, precision, color='b', alpha=0.2,\n",
    "#          where='post')\n",
    "# plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "# plt.xlabel('Recall')\n",
    "# plt.ylabel('Precision')\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.title('2-class Precision-Recall curve')\n",
    "\n",
    "# #------------------------------\n",
    "# #Print ROC Curve\n",
    "# # calculate roc curve\n",
    "# from matplotlib import pyplot\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
    "# # plot no skill\n",
    "# pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# # plot the roc curve for the model\n",
    "# pyplot.plot(fpr, tpr, marker='.')\n",
    "# # show the plot\n",
    "# pyplot.show()\n",
    "\n",
    "# #-----------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\n",
      "TRAIN: [ 62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79\n",
      "  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97\n",
      "  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115\n",
      " 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133\n",
      " 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151\n",
      " 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169\n",
      " 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184] TEST: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-77f70f8625c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_dtm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_level_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TRAIN:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TEST:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_dtm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_dtm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_level_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_level_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "#Combine classifiers level 1 & level 2\n",
    "#Cross validation 10 fold\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, cross_val_predict\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "print(skf)  \n",
    "\n",
    "for train_index, test_index in skf.split(X_train_dtm,labels_level_1):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X_train_dtm[train_index], X_train_dtm[test_index]\n",
    "    y_train, y_test = labels_level_1[train_index], labels_level_1[test_index]\n",
    "    \n",
    "#     #fit and predict first layer classifier\n",
    "#     model = SVC(kernel='linear', class_weight='balanced')\n",
    "#     clf = model.fit(X_train, y_train)\n",
    "#     predictions = clf.predict(X_test)\n",
    "    \n",
    "#     #Print out confusion matrix, True Positive, True Negative, False Positive, False Negative\n",
    "#     cm = confusion_matrix(y_test, predictions)\n",
    "#     print(cm)\n",
    "\n",
    "#     #Print Accurancy, ROC AUC, F1 Scores, Recall, Precision)\n",
    "#     print ('Accuracy:', accuracy_score(y_test, predictions))\n",
    "#     print ('ROC AUC: ', roc_auc_score(y_test,predictions))\n",
    "#     print ('Precision:', precision_score(y_test, predictions,\n",
    "#                                         average='weighted'))\n",
    "#     print ('Recall:', recall_score(y_test, predictions,\n",
    "#                                   average='weighted'))\n",
    "#     print ('F1 score:', f1_score(y_test, predictions,average='weighted'))\n",
    "#     print (classification_report(y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185, 100113)\n",
      "Row 4 has been classified as  0 and should be  1\n",
      "Row 5 has been classified as  0 and should be  1\n",
      "Row 6 has been classified as  0 and should be  1\n",
      "Row 13 has been classified as  0 and should be  1\n",
      "Row 16 has been classified as  0 and should be  1\n",
      "Row 22 has been classified as  0 and should be  1\n",
      "Row 25 has been classified as  0 and should be  1\n",
      "Row 26 has been classified as  0 and should be  1\n",
      "Row 27 has been classified as  0 and should be  1\n",
      "Row 31 has been classified as  0 and should be  1\n",
      "Row 32 has been classified as  0 and should be  1\n",
      "[[28  0]\n",
      " [ 9  0]]\n",
      "28 0 9 0\n",
      "Accuracy: 0.7567567567567568\n",
      "F1 score: 0.651975051975052\n",
      "Recall: 0.7567567567567568\n",
      "Precision: 0.5726807888970051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86        28\n",
      "           1       0.00      0.00      0.00         9\n",
      "\n",
      "   micro avg       0.76      0.76      0.76        37\n",
      "   macro avg       0.38      0.50      0.43        37\n",
      "weighted avg       0.57      0.76      0.65        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# RandomForest Model with bigrams taken from Abstract, Article Title, & Methods Section text\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "text = df['Abstract'] + df['Article Title'] + df['Methods Section']\n",
    "features = vectorizer.fit_transform(text)\n",
    "print (features.shape)\n",
    "labels = df.category_id\n",
    "features = features.todense()\n",
    "\n",
    "X_train, X_test, y_train, y_test,  = train_test_split( features, labels, stratify = labels, test_size=0.2, random_state = 0)\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "clf = model.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "for row_index, (X_test_item, prediction, label) in enumerate(zip (X_test, predictions, labels)):\n",
    "  if prediction != label:\n",
    "    print('Row', row_index, 'has been classified as ', prediction, 'and should be ', label)\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print (tn, fp, fn, tp)\n",
    "\n",
    "print ('Accuracy:', accuracy_score(y_test, predictions))\n",
    "print ('F1 score:', f1_score(y_test, predictions,average='weighted'))\n",
    "print ('Recall:', recall_score(y_test, predictions,\n",
    "                              average='weighted'))\n",
    "print ('Precision:', precision_score(y_test, predictions,\n",
    "                                    average='weighted'))\n",
    "\n",
    "print (classification_report(y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cross_val_score() got an unexpected keyword argument 'average'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-41a8ab4006fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mauc_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprecisions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cross_val_score() got an unexpected keyword argument 'average'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Run classifier with different algorithms \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(random_state=0, class_weight = 'balanced'),\n",
    "    SVC(kernel='linear', class_weight='balanced'),\n",
    "    LogisticRegression(random_state=0, class_weight = 'balanced')\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "text = df['Abstract'] + df['Article Title'] + df['Methods Section']\n",
    "features_2 = vectorizer.fit_transform(text)\n",
    "features_2 = features_2.todense()\n",
    "\n",
    "labels = df.category_id\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, features_2, labels, scoring='accuracy', cv=CV,average='weighted')\n",
    "    auc_scores = cross_val_score(model, features_2, labels, scoring='roc_auc', cv=CV,average='weighted')\n",
    "    precisions = cross_val_score(model, features_2, labels, scoring='precision', cv=CV,average='weighted')\n",
    "    recalls = cross_val_score(model, features_2, labels, scoring='recall', cv=CV,average='weighted') \n",
    "    f1_scores = cross_val_score(model, features_2, labels, scoring='f1', cv=CV,average='weighted')\n",
    "    \n",
    "    print ('acc\\t%.4f\\t%s' % (np.mean(accuracies), model_name))\n",
    "    print ('auc\\t%.4f\\t%s' % (np.mean(auc_scores), model_name))\n",
    "    print ('prec\\t%.4f\\t%s' % (np.mean(precisions), model_name))\n",
    "    print ('recall\\t%.4f\\t%s' % (np.mean(recalls), model_name))\n",
    "    print ('f1\\t%.4f\\t%s' % (np.mean(f1_scores), model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nltk version is 3.2.2.\n",
      "The scikit-learn version is 0.15.2.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "\n",
    "print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
